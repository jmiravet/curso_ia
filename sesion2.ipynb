{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo LeNet-5 con el dataset MNIST\n",
    "\n",
    "Esta libreta cuenta con toda la funcionalidad básica para descargar un dataset de TorchVision, crear un modelo sobre PyTorch desde cero y empezar a entrenar. Hay huecos en blanco señalizados con #[!] al final y enlaces a la documentación de PyTorch para que exploréis distintas opciones.\n",
    "#### Opciones a explorar\n",
    "**Función de activación:** https://pytorch.org/docs/stable/nn#non-linear-activations-weighted-sum-nonlinearity \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Opciones: Sigmoid, Tanh y ReLU \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Ejemplo: self.activacion1 = nn.Sigmoid()\n",
    "\n",
    "**Capa de Pooling:** https://pytorch.org/docs/stable/nn#pooling-layers \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Opciones: MaxPool2d y AvgPool2d \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;(Utilizar kernel_size=2, stride=2) \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Ejemplo: self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "**Optimizador:** https://pytorch.org/docs/stable/optim \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Opciones: SGD y Adam \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Hiperparámetros interesantes: learning rate, weight_decay \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Ejemplo: optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de datos\n",
    "En el siguiente enlace teneis todos los datasets disponibles en PyTorch para el reconocimiento de imágenes.\\\n",
    "https://pytorch.org/vision/0.20/datasets\n",
    "\n",
    "Dependiendo del dataset, el preprocesado de las muestras puede variar mucho. La mayoria requirere normalizar los datos.\n",
    "En la propia función de transformación que se utiliza para el preprocesado, se puede incluir aumento de datos.\\\n",
    "https://pytorch.org/vision/stable/transforms \\\n",
    "https://pytorch.org/vision/0.13/transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "# Normalizar\n",
    "train_set = torch.stack([img for img, _ in train_set], dim=0)\n",
    "mean = train_set.mean()\n",
    "std = train_set.std()\n",
    "\n",
    "batch_size = 16 # Tamaño de los lotes de muestras\n",
    "# Preprocesado de las muestras\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "# Carga el dataset de entrenamiento y validación ya normalizado\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar ejemplos de imágenes del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "label_names = train_set.classes\n",
    "for data, labels in train_loader:\n",
    "  data = data.permute(0, 2, 3, 1)\n",
    "  h, w, c = data[0].shape\n",
    "  print(f\"Dimensiones de las imagenes - altura: {h}, anchura: {w}, canales: {c}\")\n",
    "  for i in range(7):\n",
    "    plt.subplot(1,7,i+1)\n",
    "    fig.tight_layout()\n",
    "    plt.title(label_names[labels[i]])\n",
    "    plt.imshow(data[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5\n",
    "Entrada: 32x32 (imagen en escala de grises) \\\n",
    "**Extracción de carácteristicas** \\\n",
    "**Bloque 1:** \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Conv 1:** 6 filtros 5×5, padding=2, stride=1 \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Activación**  \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Pool 1:** Tamaño de ventana 2×2, stride=2\n",
    "\n",
    "**Bloque 2:** \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Conv 2:** 16 filtros 5×5, sin padding, stride=1 \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Activación**  \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Pool 2:** Tamaño de ventana 2×2, stride=2\n",
    "\n",
    "**Flatten** (aplana la imagen)\n",
    "\n",
    "**Clasificador** \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**FC 1:** 120 neuronas \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Activación**  \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**FC 2:** 84 neuronas \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Activación**  \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**FC 3:** 10 neuronas \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**Softmax** activación (Ya implícita en la función de pérdida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # Extracción de características\n",
    "        # Bloque 1\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.activacion1 = ...                                                    # [!]\n",
    "        self.pool1 = ...                                                          # [!]\n",
    "        # Bloque 2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.activacion2 = ...                                                    # [!]\n",
    "        self.pool2 = ...                                                          # [!]\n",
    "\n",
    "        # Clasificador\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.activacion3 = ...                                                    # [!]\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.activacion4 = ...                                                    # [!]\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # self.softmax = nn.Softmax() # Ya implícita en la función de pérdida\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extracción de características\n",
    "        # Bloque 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.activacion1(x)\n",
    "        x = self.pool1(x)\n",
    "        # Bloque 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.activacion2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "\n",
    "        # Clasificador\n",
    "        x = self.fc1(x)\n",
    "        x = self.activacion3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activacion4(x)\n",
    "        x = self.fc3(x) \n",
    "        # x = self.softmax(x) # Ya implícita en la función de pérdida\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "**Inicializamos:** \\\n",
    "1- Modelo \\\n",
    "2- Función de pérdida \\\n",
    "3- Optimizador\n",
    "\n",
    "**Cada época en entrenamiento:** \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Cargamos imágenes y etiquetas en dispositivo \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Ponemos los gradientes a 0 \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Forward-Pass, obtenemos las predicciones \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Función de pérdida, comparando predicciones con etiquetas \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Backward-pass, se calculan los gradientes \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Optimizador, se actualizan los pesos\n",
    "\n",
    "**Cada época en validación:** \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Cargamos imágenes y etiquetas en dispositivo \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Forward-Pass, obtenemos las predicciones \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Función de pérdida, comparando predicciones con etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()                    # Inicialización\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = ...                                                                            # [!]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Dispositivo\n",
    "model.to(device)\n",
    "\n",
    "n_epochs = 5 # Número de epocas a entrenar\n",
    "# Almacenamos métricas\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(n_epochs): \n",
    "    # Métricas\n",
    "    running_loss, correctas, total = 0.0, 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)            \n",
    "        optimizer.zero_grad() # Reinicia el optimizador\n",
    "        output = model(data) # Forward-Pass\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward() # Backward-Pass\n",
    "        optimizer.step() # Actualiza los pesos\n",
    "\n",
    "        # Métricas\n",
    "        running_loss += loss.item()\n",
    "        _, prediccion = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correctas += prediccion.eq(target).sum().item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100. * correctas / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validación del modelo\n",
    "    # Métricas\n",
    "    val_loss, correctas, total = 0.0, 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): # No calculamos gradientes en validación\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data) # Forward-Pass\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Métricas\n",
    "            val_loss += loss.item()\n",
    "            _, prediccion = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correctas += prediccion.eq(target).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100. * correctas / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Imprimimos las métricas por época\n",
    "    print(f\"Epoch [{epoch + 1}/{n_epochs}]\", end=\" | \")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\", end=\" | \")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representamos la evolución del accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, n_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, n_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy Evolution')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar y cargar un modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, path='./model.pth'):\n",
    "    state = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, optimizer, path='./model.pth'):\n",
    "    checkpoint = torch.load(path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(f\"Model loaded from {path}, starting from epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model.pth'\n",
    "# Guardar modelo\n",
    "save_model(model, optimizer, path=model_path)\n",
    "\n",
    "# Cargar modelo\n",
    "model = LeNet()\n",
    "optimizer = ... \n",
    "load_model(model, optimizer, path=model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
